Namespace(alpha=0.0, backprop=False, batch_size=128, beta=0.99, bio=False, classes_per_batch=0, classes_per_batch_until_epoch=0, cuda=True, cutout=False, dataset='MNIST', dim_in_decoder=4096, dropout=0.1, epochs=100, feat_mult=1, length=16, loss_sup='sim', loss_unsup='none', lr=0.0005, lr_decay_fact=0.25, lr_decay_milestones=[50, 75, 89, 94], model='mlp', momentum=0.0, n_holes=1, no_batch_norm=False, no_cuda=False, no_detach=False, no_print_stats=False, no_similarity_std=False, nonlin='leakyrelu', num_hidden=1024, num_layers=3, optim='adam', pre_act=False, progress_bar=False, resume='', save_dir='./results/local-error', seed=1, target_proj_size=128, weight_decay=0.0)

Net(
  (layers): ModuleList(
    (0): LocalLossBlockLinear(
      (encoder): Linear(in_features=784, out_features=1024, bias=True)
      (linear_loss): Linear(in_features=1024, out_features=1024, bias=False)
      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): LocalLossBlockLinear(
      (encoder): Linear(in_features=1024, out_features=1024, bias=True)
      (linear_loss): Linear(in_features=1024, out_features=1024, bias=False)
      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): LocalLossBlockLinear(
      (encoder): Linear(in_features=1024, out_features=1024, bias=True)
      (linear_loss): Linear(in_features=1024, out_features=1024, bias=False)
      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (layer_out): Linear(in_features=1024, out_features=10, bias=True)
)

Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0.0
)

Model mlp has 10250 parameters influenced by global loss

Train epoch=1, lr=5.00e-04, loss_local=0.1472, loss_global=0.4956, error=11.608%, mem=98MiB, max_mem=109MiB
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0608, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0461, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0403, loss_pred=0.0000, error=100.000%, num_examples=60000
Test loss_global=0.1777, error=3.720%
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0384, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0201, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0147, loss_pred=0.0000, error=100.000%, num_examples=10000

Train epoch=2, lr=5.00e-04, loss_local=0.0879, loss_global=0.2319, error=4.905%, mem=98MiB, max_mem=109MiB
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0436, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0245, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0198, loss_pred=0.0000, error=100.000%, num_examples=60000
Test loss_global=0.1128, error=2.280%
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0318, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0144, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0099, loss_pred=0.0000, error=100.000%, num_examples=10000

Train epoch=3, lr=5.00e-04, loss_local=0.0760, loss_global=0.1927, error=4.285%, mem=98MiB, max_mem=124MiB
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0393, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0201, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0165, loss_pred=0.0000, error=100.000%, num_examples=60000
Test loss_global=0.1016, error=2.170%
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0297, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0110, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0080, loss_pred=0.0000, error=100.000%, num_examples=10000

Train epoch=4, lr=5.00e-04, loss_local=0.0676, loss_global=0.1736, error=3.712%, mem=98MiB, max_mem=124MiB
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0359, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0174, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0143, loss_pred=0.0000, error=100.000%, num_examples=60000
Test loss_global=0.0996, error=2.140%
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0276, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0102, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0075, loss_pred=0.0000, error=100.000%, num_examples=10000

Train epoch=5, lr=5.00e-04, loss_local=0.0631, loss_global=0.1604, error=3.620%, mem=98MiB, max_mem=124MiB
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0339, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0159, loss_pred=0.0000, error=100.000%, num_examples=60000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0132, loss_pred=0.0000, error=100.000%, num_examples=60000
Test loss_global=0.0873, error=1.810%
Linear(in_features=784, out_features=1024, bias=True), loss_sim=0.0272, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0086, loss_pred=0.0000, error=100.000%, num_examples=10000
Linear(in_features=1024, out_features=1024, bias=True), loss_sim=0.0067, loss_pred=0.0000, error=100.000%, num_examples=10000

